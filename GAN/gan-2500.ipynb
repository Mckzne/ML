{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc99f0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T12:03:00.848105Z",
     "iopub.status.busy": "2025-04-12T12:03:00.847845Z",
     "iopub.status.idle": "2025-04-12T12:03:04.748567Z",
     "shell.execute_reply": "2025-04-12T12:03:04.747862Z"
    },
    "papermill": {
     "duration": 3.905271,
     "end_time": "2025-04-12T12:03:04.749695",
     "exception": false,
     "start_time": "2025-04-12T12:03:00.844424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5896e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:03:04.756324Z",
     "iopub.status.busy": "2025-04-12T12:03:04.756037Z",
     "iopub.status.idle": "2025-04-12T12:03:07.844577Z",
     "shell.execute_reply": "2025-04-12T12:03:07.843748Z"
    },
    "papermill": {
     "duration": 3.092723,
     "end_time": "2025-04-12T12:03:07.845682",
     "exception": false,
     "start_time": "2025-04-12T12:03:04.752959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "wan = user_secrets.get_secret(\"wandb_api\")\n",
    "wandb.login(key=wan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353509a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:03:07.852840Z",
     "iopub.status.busy": "2025-04-12T12:03:07.852583Z",
     "iopub.status.idle": "2025-04-12T17:15:43.501989Z",
     "shell.execute_reply": "2025-04-12T17:15:43.501234Z"
    },
    "papermill": {
     "duration": 18755.654635,
     "end_time": "2025-04-12T17:15:43.503176",
     "exception": false,
     "start_time": "2025-04-12T12:03:07.848541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "# from torchvision import transforms # Not explicitly needed for this setup\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import torch.nn.functional as F # For interpolation\n",
    "import traceback # For detailed error printing\n",
    "\n",
    "# --- Configuration ---\n",
    "BATCH_SIZE = 16           # Adjust based on GPU memory\n",
    "# Set high, training will likely stop due to time limit before reaching this.\n",
    "NUM_EPOCHS = 2500\n",
    "LATENT_DIM = 100          # Dimension of the noise vector\n",
    "TARGET_SIZE = (64, 64, 64)# Target size for resizing images (MUST match GAN architecture)\n",
    "SAVE_INTERVAL_HOURS = 8 # Save every 8 hours\n",
    "DATASET_PATH = '/kaggle/input/aligned-train/processed_images' # <<< YOUR DATASET PATH HERE\n",
    "WANDB_PROJECT_NAME = \"Simple-GAN-MRI-3D\" # Project name for W&B\n",
    "OUTPUT_CHANNELS = 1       # Usually 1 for grayscale MRI/CT\n",
    "LEARNING_RATE = 0.0002\n",
    "BETA1 = 0.5\n",
    "SAVE_DIR = 'saved_models_gan' # Directory to save models\n",
    "\n",
    "# Define the Generator for 3D volumes (Matches TARGET_SIZE 64x64x64)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 64 # Number of generator features in the last conv layer\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is Z (latent_dim x 1 x 1 x 1), going into a convolution\n",
    "            nn.ConvTranspose3d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm3d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4 x 4\n",
    "            nn.ConvTranspose3d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8 x 8\n",
    "            nn.ConvTranspose3d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16 x 16\n",
    "            nn.ConvTranspose3d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32 x 32\n",
    "            nn.ConvTranspose3d( ngf, output_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (output_channels) x 64 x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Ensure input is 5D: (N, C, D, H, W) where D,H,W are 1 for the latent vector\n",
    "        if input.dim() == 2: # If input is just (N, latent_dim)\n",
    "            input = input.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "        elif input.dim() != 5:\n",
    "             raise ValueError(f\"Generator expected 2D or 5D input, got {input.dim()}D\")\n",
    "        return self.main(input)\n",
    "\n",
    "# Define the Discriminator for 3D volumes (Matches TARGET_SIZE 64x64x64)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ndf = 64 # Number of discriminator features in the first conv layer\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (input_channels) x 64 x 64 x 64\n",
    "            nn.Conv3d(input_channels, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32 x 32\n",
    "            nn.Conv3d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16 x 16\n",
    "            nn.Conv3d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8 x 8\n",
    "            nn.Conv3d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4 x 4\n",
    "            nn.Conv3d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # Output size: N x 1 x 1 x 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Input should be 5D: (N, C, D, H, W)\n",
    "        if input.dim() != 5:\n",
    "             raise ValueError(f\"Discriminator expected 5D input (N, C, D, H, W), but got {input.dim()}D input with shape {input.shape}\")\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "# Custom Dataset for .nii files\n",
    "class NiftiDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_size=(64, 64, 64)): # Add target size for resizing\n",
    "        self.root_dir = root_dir\n",
    "        self.target_size = target_size\n",
    "        self.image_domain = 'mr' # Choose 'mr' or 'ct' for simple GAN\n",
    "        print(f\"NiftiDataset: Loading '{self.image_domain}' images from {root_dir} and resizing to {target_size}\")\n",
    "\n",
    "        self.file_paths = []\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise FileNotFoundError(f\"Dataset directory not found: {root_dir}\")\n",
    "\n",
    "        for pair_folder in os.listdir(root_dir):\n",
    "            pair_dir_path = os.path.join(root_dir, pair_folder)\n",
    "            if os.path.isdir(pair_dir_path):\n",
    "                 # Try finding the pair ID robustly\n",
    "                 parts = pair_folder.split('_')\n",
    "                 pair_id = parts[-1] if parts[-1].isdigit() else None\n",
    "                 if pair_id is None and len(parts) > 1 and parts[-2].isdigit(): # Handle cases like 'pair_id_extra'\n",
    "                     pair_id = parts[-2]\n",
    "                 elif pair_id is None: # Fallback if no number found at end\n",
    "                     pair_id = pair_folder # Use folder name as ID if parsing fails\n",
    "\n",
    "                 if pair_id:\n",
    "                    # Construct path based on chosen domain\n",
    "                    img_path = None # Initialize path\n",
    "                    if self.image_domain == 'mr':\n",
    "                        img_fname = f'mr_image_{pair_id}.nii'\n",
    "                        # Handle potential variations like .nii.gz\n",
    "                        potential_path = os.path.join(pair_dir_path, img_fname)\n",
    "                        if os.path.exists(potential_path):\n",
    "                            img_path = potential_path\n",
    "                        # No need to check for .gz if user confirmed only .nii\n",
    "\n",
    "                    elif self.image_domain == 'ct':\n",
    "                        img_fname = f'registered_ct_image_{pair_id}.nii'\n",
    "                        potential_path = os.path.join(pair_dir_path, img_fname)\n",
    "                        if os.path.exists(potential_path):\n",
    "                            img_path = potential_path\n",
    "                        # No need to check for .gz if user confirmed only .nii\n",
    "                    else:\n",
    "                        raise ValueError(\"image_domain must be 'mr' or 'ct'\")\n",
    "\n",
    "                    if img_path: # Check if a valid path was found\n",
    "                        self.file_paths.append(img_path)\n",
    "                    #else:\n",
    "                    #    print(f\"Warning: Expected file not found for ID {pair_id} in {pair_dir_path}\")\n",
    "                 else:\n",
    "                    print(f\"Warning: Could not determine valid pair ID for folder: {pair_folder}\")\n",
    "\n",
    "\n",
    "        if not self.file_paths:\n",
    "             print(f\"Warning: No '{self.image_domain}' image files found in the expected format within {root_dir}\")\n",
    "\n",
    "        print(f\"NiftiDataset: Found {len(self.file_paths)} image files.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "\n",
    "        try:\n",
    "            img_nii = nib.load(img_path, mmap=False) # Disable memory mapping\n",
    "            img_data = img_nii.get_fdata(dtype=np.float32, caching='unchanged')\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error loading NIfTI file {img_path}: {e}\")\n",
    "            return None # Handle loading errors\n",
    "\n",
    "        # --- Data Preprocessing ---\n",
    "        # 1. Convert to Tensor\n",
    "        img_tensor = torch.from_numpy(img_data) # Already float32\n",
    "\n",
    "        # 2. Add Channel Dimension (Ensure it's C, D, H, W)\n",
    "        if img_tensor.dim() == 3: # D, H, W -> C, D, H, W\n",
    "            img_tensor = img_tensor.unsqueeze(0)\n",
    "        elif img_tensor.dim() == 4:\n",
    "             if img_tensor.shape[0] != 1 and img_tensor.shape[-1] == 1:\n",
    "                 img_tensor = img_tensor.permute(3, 0, 1, 2)\n",
    "             elif img_tensor.shape[0] != 1:\n",
    "                 print(f\"Warning: 4D tensor has >1 channel or channel not first/last for {img_path}, shape {img_tensor.shape}. Using first channel only.\")\n",
    "                 img_tensor = img_tensor[0:1, ...]\n",
    "        if img_tensor.dim() != 4 or img_tensor.shape[0] != 1:\n",
    "             print(f\"Warning: Unexpected dimensions {img_tensor.dim()} or channels {img_tensor.shape[0]} for {img_path}. Skipping.\")\n",
    "             return None\n",
    "\n",
    "        # 3. Resize to target_size using interpolation\n",
    "        img_tensor_batched = img_tensor.unsqueeze(0)\n",
    "        try:\n",
    "            img_tensor_resized = F.interpolate(img_tensor_batched.float(), size=self.target_size, mode='trilinear', align_corners=False)\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Error interpolating image {img_path} (shape: {img_tensor_batched.shape}) to {self.target_size}: {e}\")\n",
    "             return None\n",
    "        img_tensor = img_tensor_resized.squeeze(0) # Remove batch dim\n",
    "\n",
    "        # 4. Normalize to [-1, 1] for Tanh activation\n",
    "        min_val = torch.min(img_tensor)\n",
    "        max_val = torch.max(img_tensor)\n",
    "        denominator = max_val - min_val\n",
    "        if denominator > 1e-6:\n",
    "             img_tensor = 2.0 * (img_tensor - min_val) / denominator - 1.0\n",
    "        else:\n",
    "             img_tensor = torch.zeros_like(img_tensor) - 1.0 # Normalize constant to -1\n",
    "\n",
    "        return img_tensor\n",
    "\n",
    "# Custom collate function to handle None values from dataset\n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "    try:\n",
    "        first_shape = batch[0].shape\n",
    "        for i, item in enumerate(batch):\n",
    "            if item.shape != first_shape:\n",
    "                print(f\"Error in collate_fn: Tensor shape mismatch. Item {i} shape {item.shape} != first shape {first_shape}. Skipping batch.\")\n",
    "                return None\n",
    "        return torch.stack(batch, dim=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during torch.stack in collate_fn: {e}\")\n",
    "        for i, item in enumerate(batch):\n",
    "            if isinstance(item, torch.Tensor): print(f\" Stack error - Batch item {i} shape: {item.shape}\")\n",
    "            else: print(f\" Stack error - Batch item {i} type: {type(item)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to calculate metrics (ensure shapes match)\n",
    "def calculate_metrics(real, fake):\n",
    "    try:\n",
    "        if not isinstance(real, torch.Tensor) or not isinstance(fake, torch.Tensor):\n",
    "             print(\"Warning: Non-tensor input to calculate_metrics.\")\n",
    "             return 0.0, 0.0\n",
    "        real_np = real.detach().cpu().numpy()\n",
    "        fake_np = fake.detach().cpu().numpy()\n",
    "    except AttributeError as e:\n",
    "        print(f\"Warning: Could not convert tensors to numpy for metrics calculation: {e}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    if real_np.ndim == 5: real_np = real_np.squeeze(0)\n",
    "    if fake_np.ndim == 5: fake_np = fake_np.squeeze(0)\n",
    "    if real_np.ndim == 4 and real_np.shape[0] == 1: real_np = real_np.squeeze(0)\n",
    "    if fake_np.ndim == 4 and fake_np.shape[0] == 1: fake_np = fake_np.squeeze(0)\n",
    "\n",
    "    if real_np.ndim != 3 or fake_np.ndim != 3:\n",
    "        print(f\"Warning: Cannot calculate metrics. Unexpected shapes after squeeze - Real: {real_np.shape}, Fake: {fake_np.shape}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    try:\n",
    "        real_np = real_np.astype(np.float64)\n",
    "        data_range = real_np.max() - real_np.min()\n",
    "\n",
    "        if data_range < 1e-9:\n",
    "             if np.allclose(real_np, fake_np.astype(np.float64), atol=1e-6): return 1.0, 100.0\n",
    "             else: return 0.0, 0.0\n",
    "\n",
    "        fake_np_denorm = (fake_np.astype(np.float64) + 1.0) / 2.0 * data_range + real_np.min()\n",
    "\n",
    "        min_dim = min(real_np.shape)\n",
    "        win_size = min(7, min_dim)\n",
    "        if win_size % 2 == 0: win_size -= 1\n",
    "\n",
    "        if win_size < 3: ssim_value = 0.0\n",
    "        else: ssim_value = ssim(real_np, fake_np_denorm, data_range=data_range, channel_axis=None, win_size=win_size, gaussian_weights=True, use_sample_covariance=False)\n",
    "\n",
    "        psnr_value = psnr(real_np, fake_np_denorm, data_range=data_range)\n",
    "        if np.isinf(psnr_value): psnr_value = 100.0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {e}\")\n",
    "        print(f\"Metric calculation error details - Real shape: {real_np.shape}, Fake shape: {fake_np.shape}, Denorm fake shape: {fake_np_denorm.shape if 'fake_np_denorm' in locals() else 'N/A'}, Data Range: {data_range if 'data_range' in locals() else 'N/A'}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    return float(ssim_value), float(psnr_value)\n",
    "\n",
    "# Function to save the model\n",
    "def save_model(generator, discriminator, optimizer_G, optimizer_D, epoch, elapsed_time, latent_dim, target_size, save_dir=SAVE_DIR):\n",
    "    \"\"\"Saves the generator, discriminator, optimizers, and training state.\"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        try:\n",
    "            os.makedirs(save_dir)\n",
    "            print(f\"Created save directory: {save_dir}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating save directory {save_dir}: {e}\")\n",
    "            return\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_filename = f'gan_model_epoch{epoch}_time{elapsed_time/3600:.2f}h_{timestamp}.pth'\n",
    "    model_path = os.path.join(save_dir, model_filename)\n",
    "\n",
    "    try:\n",
    "        # Save state dicts directly (no need to move models if loading on same device type)\n",
    "        generator_state = generator.state_dict()\n",
    "        discriminator_state = discriminator.state_dict()\n",
    "\n",
    "        save_data = {\n",
    "            'epoch': epoch,\n",
    "            'generator_state_dict': generator_state,\n",
    "            'discriminator_state_dict': discriminator_state,\n",
    "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            'elapsed_time_seconds': elapsed_time,\n",
    "            'latent_dim': latent_dim,\n",
    "            'target_size': target_size,\n",
    "            'wandb_project': WANDB_PROJECT_NAME,\n",
    "            'dataset_path': DATASET_PATH\n",
    "        }\n",
    "        torch.save(save_data, model_path)\n",
    "        print(f\"Model saved successfully to {model_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model to {model_path}: {e}\")\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_gan(generator, discriminator, dataloader, num_epochs, device, latent_dim, target_size, save_interval_hours=8):\n",
    "    global global_start_time # Make start_time accessible\n",
    "\n",
    "    # Initialize W&B\n",
    "    wandb_active = False\n",
    "    run = None\n",
    "    try:\n",
    "        run = wandb.init(project=WANDB_PROJECT_NAME, config={\n",
    "            \"learning_rate\": LEARNING_RATE, \"beta1\": BETA1, \"batch_size\": dataloader.batch_size if dataloader.batch_size else BATCH_SIZE,\n",
    "            \"num_epochs\": num_epochs, \"latent_dim\": latent_dim, \"target_image_size\": target_size,\n",
    "            \"dataset_path\": DATASET_PATH, \"architecture\": \"SimpleDCGAN3D\", \"device\": str(device)\n",
    "        })\n",
    "        print(f\"WandB run initialized: {run.name} - {run.url}\")\n",
    "        wandb_active = True\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing WandB: {e}. Training will continue without logging.\")\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "\n",
    "    # Fixed noise for visualization\n",
    "    vis_batch_size = min(8, dataloader.batch_size if dataloader.batch_size else BATCH_SIZE)\n",
    "    if vis_batch_size <= 0: vis_batch_size = 1\n",
    "    fixed_noise = torch.randn(vis_batch_size, latent_dim, 1, 1, 1, device=device)\n",
    "\n",
    "    global_start_time = time.time() # Record start time\n",
    "    print(f\"Starting training on {device}...\")\n",
    "    print(f\"Target image size: {target_size}\")\n",
    "    print(f\"Number of epochs: {num_epochs}\")\n",
    "    print(f\"Batch size: {dataloader.batch_size if dataloader.batch_size else BATCH_SIZE}\")\n",
    "    print(f\"Save interval: {save_interval_hours} hours ({save_interval_hours * 3600} seconds)\")\n",
    "    # last_save_time = global_start_time # Not needed for single save trigger\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    current_epoch = 0 # Track epoch number (1-based)\n",
    "    training_interrupted_by_time = False # Flag to indicate if time limit caused break\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            current_epoch = epoch + 1\n",
    "            epoch_start_time = time.time()\n",
    "            g_loss_epoch_total = 0.0\n",
    "            d_loss_epoch_total = 0.0\n",
    "            num_batches_processed = 0\n",
    "            last_real_images_for_metrics = None # Store last valid real batch for metrics\n",
    "\n",
    "            generator.train()\n",
    "            discriminator.train()\n",
    "\n",
    "            print(f\"\\n--- Starting Epoch {current_epoch}/{num_epochs} ---\")\n",
    "\n",
    "            # Check time before starting epoch batches\n",
    "            elapsed_time = time.time() - global_start_time\n",
    "            if elapsed_time >= save_interval_hours * 3600:\n",
    "                 print(f\"\\n--- Save interval ({save_interval_hours} hours) reached BEFORE starting Epoch {current_epoch}. Saving model now. ---\")\n",
    "                 save_model(generator, discriminator, optimizer_G, optimizer_D, current_epoch -1 , elapsed_time, latent_dim, target_size)\n",
    "                 print(\"--- Exiting training loop after saving ---\")\n",
    "                 training_interrupted_by_time = True\n",
    "                 break # Exit the main training loop\n",
    "\n",
    "            # --- Batch Loop ---\n",
    "            for i, data in enumerate(dataloader, 0):\n",
    "                if data is None: continue # Skip empty batches from collate_fn\n",
    "\n",
    "                real_images = data.to(device)\n",
    "                current_batch_size = real_images.size(0)\n",
    "                if current_batch_size == 0: continue\n",
    "\n",
    "                # Store the first valid batch for end-of-epoch metrics if needed\n",
    "                if last_real_images_for_metrics is None:\n",
    "                     last_real_images_for_metrics = real_images.detach() # Detach if only used for metrics\n",
    "\n",
    "                if real_images.dim() != 5:\n",
    "                     print(f\"Warning: Skipping batch {i}. Expected 5D tensor, got {real_images.dim()}D with shape {real_images.shape}\")\n",
    "                     continue\n",
    "\n",
    "                # --- Train Discriminator ---\n",
    "                discriminator.zero_grad()\n",
    "                # Real\n",
    "                label_real = torch.full((current_batch_size,), 1.0, dtype=torch.float, device=device)\n",
    "                output_real = discriminator(real_images).view(-1)\n",
    "                errD_real = nn.BCELoss()(output_real, label_real)\n",
    "                errD_real.backward()\n",
    "                D_x = output_real.mean().item()\n",
    "                # Fake\n",
    "                noise = torch.randn(current_batch_size, latent_dim, 1, 1, 1, device=device)\n",
    "                fake_images = generator(noise)\n",
    "                label_fake = torch.full((current_batch_size,), 0.0, dtype=torch.float, device=device)\n",
    "                output_fake = discriminator(fake_images.detach()).view(-1)\n",
    "                errD_fake = nn.BCELoss()(output_fake, label_fake)\n",
    "                errD_fake.backward()\n",
    "                D_G_z1 = output_fake.mean().item()\n",
    "                # Update D\n",
    "                errD = errD_real + errD_fake\n",
    "                optimizer_D.step()\n",
    "\n",
    "                # --- Train Generator ---\n",
    "                generator.zero_grad()\n",
    "                label_real_for_G = torch.full((current_batch_size,), 1.0, dtype=torch.float, device=device)\n",
    "                output_fake_for_G = discriminator(fake_images).view(-1)\n",
    "                errG = nn.BCELoss()(output_fake_for_G, label_real_for_G)\n",
    "                errG.backward()\n",
    "                D_G_z2 = output_fake_for_G.mean().item()\n",
    "                # Update G\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # --- Logging & Tracking ---\n",
    "                g_loss_epoch_total += errG.item()\n",
    "                d_loss_epoch_total += errD.item()\n",
    "                num_batches_processed += 1\n",
    "\n",
    "                # Print progress periodically\n",
    "                if i % 50 == 0 or i == len(dataloader) - 1:\n",
    "                    print(f'  [{current_epoch}/{num_epochs}][{i}/{len(dataloader)-1}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} -> {D_G_z2:.4f}')\n",
    "            # --- End of Batch Loop ---\n",
    "\n",
    "            # --- End of Epoch Processing ---\n",
    "            if num_batches_processed == 0:\n",
    "                 print(f\"Epoch [{current_epoch}/{num_epochs}] skipped - no valid batches processed.\")\n",
    "                 continue # Skip logging/saving for this epoch\n",
    "\n",
    "            avg_g_loss = g_loss_epoch_total / num_batches_processed\n",
    "            avg_d_loss = d_loss_epoch_total / num_batches_processed\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "            print(f\"Epoch [{current_epoch}/{num_epochs}] completed in {epoch_time:.2f}s. Avg Loss_D: {avg_d_loss:.4f}, Avg Loss_G: {avg_g_loss:.4f}\")\n",
    "\n",
    "            # --- W&B Logging ---\n",
    "            if wandb_active:\n",
    "                log_dict = {\n",
    "                    \"Epoch\": current_epoch, \"Average Generator Loss\": avg_g_loss, \"Average Discriminator Loss\": avg_d_loss,\n",
    "                    \"Epoch Time (s)\": epoch_time, \"D(x) (last batch avg)\": D_x if 'D_x' in locals() else 0.0,\n",
    "                    \"D(G(z)) (last batch avg)\": D_G_z2 if 'D_G_z2' in locals() else 0.0\n",
    "                }\n",
    "\n",
    "                # Log Images & Metrics periodically\n",
    "                if current_epoch % 5 == 0 or epoch == num_epochs - 1:\n",
    "                     generator.eval()\n",
    "                     with torch.no_grad(): fake_fixed = generator(fixed_noise).detach()\n",
    "                     generator.train()\n",
    "\n",
    "                     # Log images\n",
    "                     try:\n",
    "                         if fake_fixed.shape[0] > 0:\n",
    "                            middle_slice_idx = fake_fixed.shape[2] // 2\n",
    "                            wandb_images = [wandb.Image(img[0, middle_slice_idx, :, :].cpu().numpy(), caption=f\"Epoch {current_epoch}\") for img in fake_fixed]\n",
    "                            log_dict[\"Generated Images (Fixed Noise, Middle Slice)\"] = wandb_images\n",
    "                     except Exception as img_log_e: print(f\"Warning: Error creating WandB images for epoch {current_epoch}: {img_log_e}\")\n",
    "\n",
    "                     # Calculate/log metrics\n",
    "                     # Use the first image from the *first* valid batch stored, and first fixed fake image\n",
    "                     if last_real_images_for_metrics is not None and last_real_images_for_metrics.shape[0] > 0 and fake_fixed.shape[0] > 0:\n",
    "                         try:\n",
    "                             ssim_val, psnr_val = calculate_metrics(last_real_images_for_metrics[0], fake_fixed[0])\n",
    "                             log_dict[\"SSIM (Sample)\"] = ssim_val; log_dict[\"PSNR (Sample)\"] = psnr_val\n",
    "                             print(f\"Epoch {current_epoch} Sample Metrics - SSIM: {ssim_val:.4f}, PSNR: {psnr_val:.4f} dB\")\n",
    "                         except Exception as metric_e: print(f\"Error calculating metrics for epoch {current_epoch}: {metric_e}\"); log_dict[\"SSIM (Sample)\"] = 0.0; log_dict[\"PSNR (Sample)\"] = 0.0\n",
    "                     else: print(f\"Skipping metrics calculation for epoch {current_epoch}, no valid real/fake images available.\")\n",
    "\n",
    "                # Log dictionary to W&B\n",
    "                try: wandb.log(log_dict, step=current_epoch)\n",
    "                except Exception as log_e: print(f\"  Error during wandb.log for Epoch {current_epoch}: {log_e}\")\n",
    "\n",
    "            # --- Check Save Interval (End of Epoch) ---\n",
    "            # This check is slightly redundant if the check at the start of the epoch works,\n",
    "            # but acts as a failsafe in case an epoch takes exactly long enough.\n",
    "            elapsed_time = time.time() - global_start_time\n",
    "            # total_time_hours = elapsed_time / 3600 # Calculate if needed for print\n",
    "            if elapsed_time >= save_interval_hours * 3600:\n",
    "                print(f\"\\n--- Save interval ({save_interval_hours} hours) reached END of Epoch {current_epoch}. Saving model. ---\")\n",
    "                save_model(generator, discriminator, optimizer_G, optimizer_D, current_epoch, elapsed_time, latent_dim, target_size)\n",
    "                print(\"--- Exiting training loop after saving ---\")\n",
    "                training_interrupted_by_time = True\n",
    "                break # Exit the main training loop\n",
    "\n",
    "        # --- End of Epoch Loop (Natural Completion or Break) ---\n",
    "        # No need for the erroneous break here anymore\n",
    "\n",
    "    # --- End of Training Function Try Block ---\n",
    "    except KeyboardInterrupt: # Handle manual interruption (Ctrl+C)\n",
    "        print(\"\\n--- Training interrupted manually (KeyboardInterrupt) ---\")\n",
    "        print(\"Attempting to save final model state...\")\n",
    "        current_elapsed_time = time.time() - global_start_time\n",
    "        if 'optimizer_G' in locals() and 'optimizer_D' in locals():\n",
    "             save_model(generator, discriminator, optimizer_G, optimizer_D, current_epoch, current_elapsed_time, latent_dim, target_size)\n",
    "        else: print(\"Cannot save model state - optimizers not fully initialized.\")\n",
    "        training_interrupted_by_time = True # Set flag to indicate not a normal finish\n",
    "\n",
    "    except Exception as train_e:\n",
    "        print(f\"\\n--- An error occurred during training at Epoch {current_epoch}: {train_e} ---\")\n",
    "        traceback.print_exc() # Print detailed traceback\n",
    "        print(\"Attempting to save model state due to error...\")\n",
    "        current_elapsed_time = time.time() - global_start_time\n",
    "        if 'optimizer_G' in locals() and 'optimizer_D' in locals():\n",
    "            save_model(generator, discriminator, optimizer_G, optimizer_D, current_epoch, current_elapsed_time, latent_dim, target_size)\n",
    "        else: print(\"Cannot save model state - optimizers not fully initialized.\")\n",
    "        training_interrupted_by_time = True # Set flag to indicate not a normal finish\n",
    "    finally:\n",
    "        # This block executes whether the loop finished normally, broke, or had an exception\n",
    "        print(\"\\n--- Training Function Ended ---\")\n",
    "        # Save final model if training finished all epochs *without* being interrupted by time or error\n",
    "        if not training_interrupted_by_time and current_epoch == num_epochs:\n",
    "             print(\"Saving final model after completing all epochs...\")\n",
    "             final_elapsed_time = time.time() - global_start_time\n",
    "             if 'optimizer_G' in locals() and 'optimizer_D' in locals():\n",
    "                save_model(generator, discriminator, optimizer_G, optimizer_D, current_epoch, final_elapsed_time, latent_dim, target_size)\n",
    "             else: print(\"Cannot save final model - optimizers not available.\")\n",
    "\n",
    "        if wandb_active and run:\n",
    "            try:\n",
    "                wandb.finish()\n",
    "                print(\"WandB run finished.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error finishing WandB run: {e}\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Setup ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    global_start_time = 0.0 # Initialize; will be set in train_gan\n",
    "\n",
    "    # --- Models ---\n",
    "    print(\"Initializing models...\")\n",
    "    try:\n",
    "        generator = Generator(LATENT_DIM, output_channels=OUTPUT_CHANNELS).to(device)\n",
    "        discriminator = Discriminator(input_channels=OUTPUT_CHANNELS).to(device)\n",
    "        print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters() if p.requires_grad)}\")\n",
    "        print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters() if p.requires_grad)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing models: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # --- Data ---\n",
    "    print(f\"\\nLoading dataset from: {DATASET_PATH}, Target size: {TARGET_SIZE}\")\n",
    "    try:\n",
    "        dataset = NiftiDataset(root_dir=DATASET_PATH, target_size=TARGET_SIZE)\n",
    "        if len(dataset) == 0:\n",
    "             raise ValueError(\"Dataset initialization resulted in zero valid files.\")\n",
    "\n",
    "        dataloader = DataLoader(dataset,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                num_workers=2,\n",
    "                                pin_memory=True if device.type == 'cuda' else False,\n",
    "                                collate_fn=collate_fn,\n",
    "                                drop_last=True)\n",
    "\n",
    "        print(f\"Dataset loaded. Number of samples: {len(dataset)}. Number of batches: {len(dataloader)}\")\n",
    "        if len(dataloader) == 0:\n",
    "             raise ValueError(\"DataLoader is empty after collation. Check dataset/processing steps.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset or creating dataloader: {e}\")\n",
    "        traceback.print_exc()\n",
    "        exit(1)\n",
    "\n",
    "    # --- Train ---\n",
    "    print(\"\\nStarting training process...\")\n",
    "    train_gan(generator=generator,\n",
    "              discriminator=discriminator,\n",
    "              dataloader=dataloader,\n",
    "              num_epochs=NUM_EPOCHS,\n",
    "              device=device,\n",
    "              latent_dim=LATENT_DIM,\n",
    "              target_size=TARGET_SIZE,\n",
    "              save_interval_hours=SAVE_INTERVAL_HOURS)\n",
    "\n",
    "    print(\"\\nMain script execution finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04676087",
   "metadata": {
    "papermill": {
     "duration": 0.247355,
     "end_time": "2025-04-12T17:15:43.997637",
     "exception": false,
     "start_time": "2025-04-12T17:15:43.750282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modified test evaluation code\n",
    "print(\"\\nLoading test dataset...\")\n",
    "test_dataset = NiftiDataset(\n",
    "    root_dir='/kaggle/input/mrict-test/processed_images',\n",
    "    target_size=(64, 64, 64),\n",
    "    modality='mr',\n",
    "    paired_images=True\n",
    ")\n",
    "\n",
    "# Set batch size to match dataset size\n",
    "test_batch_size = 8  # Divides evenly into 29 (8*3 + 5*1 = 29)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}, Batches: {len(test_loader)}\")\n",
    "\n",
    "# Evaluation loop\n",
    "generator.eval()\n",
    "total_ssim = 0\n",
    "total_psnr = 0\n",
    "total_samples = 0  # Track actual number of processed samples\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (real_mr, real_ct) in enumerate(test_loader):\n",
    "        current_batch_size = real_mr.size(0)  # Actual samples in this batch\n",
    "        real_mr = real_mr.to(device)\n",
    "        fake_ct = generator(real_mr)\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        fake_ct_np = fake_ct.detach().cpu().numpy()\n",
    "        real_ct_np = real_ct.detach().cpu().numpy()\n",
    "        \n",
    "        # Calculate metrics for current batch\n",
    "        batch_ssim = ssim(fake_ct_np, real_ct_np) * current_batch_size\n",
    "        batch_psnr = psnr(fake_ct_np, real_ct_np) * current_batch_size\n",
    "        \n",
    "        total_ssim += batch_ssim\n",
    "        total_psnr += batch_psnr\n",
    "        total_samples += current_batch_size\n",
    "\n",
    "        # Save all test images with original filenames\n",
    "        for j in range(current_batch_size):\n",
    "            idx = i * test_batch_size + j\n",
    "            orig_filename = test_dataset.filenames[idx]\n",
    "            save_filename = f\"test_result_{orig_filename.split('.')[0]}.png\"\n",
    "            save_image(fake_ct[j], save_filename)\n",
    "\n",
    "# Calculate weighted averages\n",
    "avg_ssim = total_ssim / total_samples\n",
    "avg_psnr = total_psnr / total_samples\n",
    "print(f\"\\nTest Results (n={total_samples}) - SSIM: {avg_ssim:.4f}, PSNR: {avg_psnr:.2f} dB\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7119426,
     "sourceId": 11372430,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18770.925666,
   "end_time": "2025-04-12T17:15:47.290625",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T12:02:56.364959",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
